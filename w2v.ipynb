{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3352b98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import nltk\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.lancaster import LancasterStemmer  \n",
    "from nltk.corpus import words\n",
    "from copy import deepcopy\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "306eb585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_text(text):\n",
    "    text = re.sub(r\"\\d+\", \"\", text.lower())\n",
    "    for i in string.punctuation:\n",
    "        text = text.replace(i,\"\")\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    tokens = word_tokenize(text)\n",
    "    sample = [i for i in tokens if not i in stop_words]\n",
    "    # lancaster_\n",
    "    stemmer = LancasterStemmer() \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    \n",
    "    \n",
    "    return [lemmatizer.lemmatize(word) for word in sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c23b2185",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"movie_data.csv\")\n",
    "data.head()\n",
    "review = data[\"review\"] # create a data frame with only data \n",
    "review = review.apply(preproc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdce1d2f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(review, size=500, window=10, min_count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51931102",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def generate_vec(wordlist):\n",
    "    dic = set(model.wv.index2word)\n",
    "    feature = np.zeros(500)\n",
    "    count = 0\n",
    "    for word in wordlist:\n",
    "        if word in dic:\n",
    "            feature = np.add(model.wv[word], feature)\n",
    "            count += 1\n",
    "    \n",
    "    return list(feature/count)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07a6f6f1",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def split_train(original_train_data, size=5000):\n",
    "    return original_train_data[:size], original_train_data[size:size+2000]\n",
    "\n",
    "def binary_transform(sentiment):\n",
    "    if sentiment == \"positive\":\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ca16be7",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "label = data[\"sentiment\"]\n",
    "train_X, val_X = split_train(review)\n",
    "train_y, val_y = split_train(label)\n",
    "train_y = train_y.apply(binary_transform)\n",
    "# cleandata = pd.DataFrame({\"label\":label, \"wordlist\":review})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b7a817e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_X = train_X.apply(generate_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b9275ce",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "X = np.zeros(5000*500).reshape(5000,500)\n",
    "Y = np.array(train_y)\n",
    "for i in range(5000):\n",
    "    X[i] = train_X[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02d930ee",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(C=2)\n",
    "clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d852fba",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "VX = val_X.apply(generate_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9d8c223",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "Vy = val_y.apply(binary_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a56fbbd",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = 0\n",
    "for i in range(2000):\n",
    "    if clf.predict([VX.values[i]])[0] != Vy.values[i]:\n",
    "        error += 1\n",
    "error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38] *",
   "language": "python",
   "name": "conda-env-py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
