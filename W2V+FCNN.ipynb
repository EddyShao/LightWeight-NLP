{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3352b98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import nltk\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.lancaster import LancasterStemmer  \n",
    "from nltk.corpus import words\n",
    "from copy import deepcopy\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn import svm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential,optimizers\n",
    "from tensorflow.keras.layers import Dense,BatchNormalization,Dropout,Activation\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow_hub as hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "306eb585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_text(text):\n",
    "    text = re.sub(r\"\\d+\", \"\", text.lower())\n",
    "    for i in string.punctuation:\n",
    "        text = text.replace(i,\"\")\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    tokens = word_tokenize(text)\n",
    "    sample = [i for i in tokens if not i in stop_words]\n",
    "    # lancaster_\n",
    "    stemmer = LancasterStemmer() \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    \n",
    "    \n",
    "    return [lemmatizer.lemmatize(word) for word in sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c23b2185",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"movie_data.csv\")\n",
    "data.head()\n",
    "review = data[\"review\"] # create a data frame with only data \n",
    "review = review.apply(preproc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fdce1d2f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(review[:40000], vector_size=500, window=10, min_count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "51931102",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "dic = set(model.wv.index_to_key)\n",
    "def generate_vec(wordlist):\n",
    "    feature = np.zeros(500)\n",
    "    count = 0\n",
    "    for word in wordlist:\n",
    "        if word in dic:\n",
    "            feature = np.add(model.wv[word], feature)\n",
    "            count += 1\n",
    "    \n",
    "    return list(feature/count)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "07a6f6f1",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def split_train(original_train_data, size=10000):\n",
    "    return original_train_data[:size], original_train_data[40000:40000+2000]\n",
    "\n",
    "def binary_transform(sentiment):\n",
    "    if sentiment == \"positive\":\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4da6c95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = data[\"sentiment\"].apply(binary_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5ca16be7",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_X, val_X = split_train(review)\n",
    "train_y, val_y = split_train(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5b7a817e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_X = train_X.apply(generate_vec).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "13349415",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X = val_X.apply(generate_vec).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7b9275ce",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "X = np.zeros(10000*500).reshape(10000,500)\n",
    "Y = np.array(train_y)\n",
    "for i in range(5000):\n",
    "    X[i] = train_X[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "40e95ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vt = np.zeros(2000*500).reshape(2000,500)\n",
    "y = np.array(val_y)\n",
    "for i in range(2000):\n",
    "    x_vt[i] = val_X[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "07a42191",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X, test_X = x_vt[:1000], x_vt[1000:]\n",
    "val_y, test_y = y[:1000], y[1000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "64b65d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Sequential([\n",
    "            Dense(16, input_dim=500, activation=\"relu\"),\n",
    "            #Dense(64, activation=\"relu\"),\n",
    "            Dense(32, activation=\"relu\"),\n",
    "            #Dense(64, activation=\"relu\", kernel_regularizer=regularizers.l2(0.0001)),\n",
    "            Dense(1, activation=\"sigmoid\")\n",
    "        ])\n",
    "\n",
    "model_2.compile(\n",
    "            optimizer=\"Adam\",\n",
    "            loss=\"binary_crossentropy\",\n",
    "            metrics=[\"binary_accuracy\"]\n",
    "        )\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=3, min_lr=0.001)\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss',\n",
    "                   min_delta=0, patience=2, verbose=1, mode='auto',\n",
    "                   baseline=None, restore_best_weights=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d94a0d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.6151 - binary_accuracy: 0.5998 - val_loss: 0.3450 - val_binary_accuracy: 0.8550\n",
      "Epoch 2/300\n",
      "313/313 [==============================] - 0s 810us/step - loss: 0.5086 - binary_accuracy: 0.6828 - val_loss: 0.3364 - val_binary_accuracy: 0.8610\n",
      "Epoch 3/300\n",
      "313/313 [==============================] - 0s 786us/step - loss: 0.5102 - binary_accuracy: 0.6796 - val_loss: 0.3454 - val_binary_accuracy: 0.8670\n",
      "Epoch 4/300\n",
      "313/313 [==============================] - 0s 786us/step - loss: 0.5045 - binary_accuracy: 0.6882 - val_loss: 0.3391 - val_binary_accuracy: 0.8620\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model_2.fit(\n",
    "            x=X,\n",
    "            y=Y,\n",
    "            batch_size=32,\n",
    "            epochs=300,\n",
    "            verbose=1,\n",
    "            validation_data=(val_X, val_y),\n",
    "            callbacks=[reduce_lr, es],\n",
    "            shuffle=True\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "38901346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Count: 154\n",
      "Accuracy: 84.6%\n"
     ]
    }
   ],
   "source": [
    "prediction = model_2.predict(test_X)\n",
    "        \n",
    "for i in range(len(prediction)):\n",
    "    if prediction[i] <= 0.5:\n",
    "        prediction[i] = 0\n",
    "    else:\n",
    "        prediction[i] = 1\n",
    "        \n",
    "error_count = 0 \n",
    "for i in range(len(prediction)):\n",
    "    if prediction[i] != test_y[i]:\n",
    "        error_count += 1\n",
    "\n",
    "print(\"Error Count: {}\".format(error_count))\n",
    "print(\"Accuracy: {}%\".format(((len(test_y)-error_count)/len(test_y))*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38] *",
   "language": "python",
   "name": "conda-env-py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
