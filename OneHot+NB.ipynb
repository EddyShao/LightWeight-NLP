{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dried-johnson",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import nltk\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.lancaster import LancasterStemmer  \n",
    "from nltk.corpus import words\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "accessory-gibraltar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"movie_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "documentary-pharmacology",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_text(text):\n",
    "    text = re.sub(r\"\\d+\", \"\", text.lower())\n",
    "    for i in string.punctuation:\n",
    "        text = text.replace(i,\"\")\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    tokens = word_tokenize(text)\n",
    "    sample = [i for i in tokens if not i in stop_words]\n",
    "    lancaster_stemmer = LancasterStemmer() \n",
    "    \n",
    "    return [lancaster_stemmer.stem(word) for word in sample]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "infectious-focus",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = data[\"review\"] # create a data frame with only data \n",
    "review = review.apply(preproc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "890b2667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [on, review, ment, watch, oz, episod, youl, ho...\n",
       "1        [wond, littl, produc, br, br, film, techn, una...\n",
       "2        [thought, wond, way, spend, tim, hot, sum, wee...\n",
       "3        [bas, ther, famy, littl, boy, jak, think, ther...\n",
       "4        [pet, mat, lov, tim, money, vis, stun, film, w...\n",
       "                               ...                        \n",
       "49995    [thought, movy, right, good, job, wasnt, cre, ...\n",
       "49996    [bad, plot, bad, dialog, bad, act, idiot, dire...\n",
       "49997    [cathol, taught, paroch, el, schools, nun, tau...\n",
       "49998    [im, going, disagr, prevy, com, sid, maltin, o...\n",
       "49999    [on, expect, star, trek, movy, high, art, fan,...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "objective-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wordlist(original_train_data, threshold=26):\n",
    "    \"\"\"\n",
    "    Create a word list from the original training set.\n",
    "    Only get a word if it appears in at least $threshold emails.\n",
    "    Returns:\n",
    "        * a python list containing all the words that occur in at least $threshold emails.\n",
    "    \"\"\"\n",
    "    \n",
    "    c = Counter()\n",
    "    for i in original_train_data:\n",
    "        c.update(i)\n",
    "\n",
    "    c = dict(c)\n",
    "    c = {k:v for k,v in c.items() if v >= threshold}\n",
    "    \n",
    "    return list(c.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5f79708",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist = create_wordlist(review[:40000], 26)\n",
    "wordlist.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0555cb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train(original_train_data, size=30000):\n",
    "    return original_train_data[:size], original_train_data[size:]\n",
    "def binary_transform(sentiment):\n",
    "    if sentiment == \"positive\":\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "960c3d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>wordlist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30000</th>\n",
       "      <td>1</td>\n",
       "      <td>[on, quit, cartoon, scooby, doo, film, scooby,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30001</th>\n",
       "      <td>0</td>\n",
       "      <td>[on, silliest, movy, ev, misfortun, watch, exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30002</th>\n",
       "      <td>0</td>\n",
       "      <td>[reason, fatherinlaw, gav, cop, tap, think, gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30003</th>\n",
       "      <td>1</td>\n",
       "      <td>[may, hard, explain, film, masterpiec, perhap,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30004</th>\n",
       "      <td>0</td>\n",
       "      <td>[show, worst, show, ev, nor, famy, writ, produ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>1</td>\n",
       "      <td>[thought, movy, right, good, job, wasnt, cre, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>0</td>\n",
       "      <td>[bad, plot, bad, dialog, bad, act, idiot, dire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>0</td>\n",
       "      <td>[cathol, taught, paroch, el, schools, nun, tau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>0</td>\n",
       "      <td>[im, going, disagr, prevy, com, sid, maltin, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>0</td>\n",
       "      <td>[on, expect, star, trek, movy, high, art, fan,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                           wordlist\n",
       "30000      1  [on, quit, cartoon, scooby, doo, film, scooby,...\n",
       "30001      0  [on, silliest, movy, ev, misfortun, watch, exp...\n",
       "30002      0  [reason, fatherinlaw, gav, cop, tap, think, gr...\n",
       "30003      1  [may, hard, explain, film, masterpiec, perhap,...\n",
       "30004      0  [show, worst, show, ev, nor, famy, writ, produ...\n",
       "...      ...                                                ...\n",
       "49995      1  [thought, movy, right, good, job, wasnt, cre, ...\n",
       "49996      0  [bad, plot, bad, dialog, bad, act, idiot, dire...\n",
       "49997      0  [cathol, taught, paroch, el, schools, nun, tau...\n",
       "49998      0  [im, going, disagr, prevy, com, sid, maltin, o...\n",
       "49999      0  [on, expect, star, trek, movy, high, art, fan,...\n",
       "\n",
       "[20000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = data[\"sentiment\"]\n",
    "label = label.apply(binary_transform)\n",
    "cleandata = pd.DataFrame({\"label\":label, \"wordlist\":review})\n",
    "train, validation = split_train(cleandata)\n",
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a03c4e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, wordlist):\n",
    "        self.wordlist = wordlist\n",
    "\n",
    "    def count_labels(self, data):\n",
    "        \"\"\"\n",
    "        Count the number of positive labels and negative labels.\n",
    "        Returns (a tuple or a numpy array of two elements):\n",
    "            * negative_count: a non-negative integer, which represents the number of negative labels (non-spam emails);\n",
    "            * positive_count: a non-negative integer, which represents the number of positive labels (spam emails).\n",
    "        \"\"\"\n",
    "        # TODO\n",
    "        c = Counter(data[:,0])\n",
    "        return np.array([c[0], c[1]])\n",
    "\n",
    "    def count_words(self, wordlist, data):\n",
    "        \"\"\"\n",
    "        Count the number of times that each word appears in emails under a given label.\n",
    "        Returns (a numpy array):\n",
    "            * word_counts: a numpy array with shape (2, L), where L is the length of $wordlist,\n",
    "                - word_counts[0, i] represents the number of times that word $wordlist[i] appears in non-spam (negative) emails, and\n",
    "                - word_counts[1, i] represents the number of times that word $wordlist[i] appears in spam (positive) emails.\n",
    "        \"\"\"\n",
    "        L = len(wordlist)\n",
    "        positive = data[data[:,0]==1][:,1]\n",
    "        negative = data[data[:,0]==0][:,1]\n",
    "        \n",
    "        output = np.zeros(2*L).reshape(2, L)\n",
    "        \n",
    "        for review in negative:\n",
    "            review = set(review)\n",
    "            for i in range(L):\n",
    "                if wordlist[i] in review:\n",
    "                    output[0, i] += 1\n",
    "            \n",
    "        for review in positive:\n",
    "            review = set(review)\n",
    "            for j in range(L):\n",
    "                if wordlist[j] in review:\n",
    "                    output[1, j] += 1\n",
    "        \n",
    "        return output\n",
    "            \n",
    "\n",
    "    def calculate_probability(self, label_counts, word_counts):\n",
    "        \"\"\"\n",
    "        Calculate the probabilities, both the prior and likelihood.\n",
    "        Returns (a pair of numpy array):\n",
    "            * prior_probs: a numpy array with shape (2, ), only two elements, where\n",
    "                - prior_probs[0] is the prior probability of negative labels, and\n",
    "                - prior_probs[1] is the prior probability of positive labels.\n",
    "            * likelihood_probs: a numpy array with shape (2, L), where L is the length of the word list,\n",
    "                - likelihood_probs[0, i] represents the likelihood probability of the $i-th word in the word list, given that the email is non-spam (negative), and\n",
    "                - likelihood_probs[1, i] represents the likelihood probability of the $i-th word in the word list, given that the email is spam (positive).\n",
    "        \"\"\"\n",
    "        # TODO\n",
    "        prior_probs = deepcopy(label_counts)/sum(label_counts)\n",
    "        \n",
    "        L = word_counts.shape[1]\n",
    "        likelihood_probs = np.zeros(2*L).reshape(2, L)\n",
    "        \n",
    "        for i in range(L):\n",
    "            likelihood_probs[0, i] = (word_counts[0, i] + 1)/(label_counts[0] + 2)\n",
    "            likelihood_probs[1, i] = (word_counts[1, i] + 1)/(label_counts[1] + 2)\n",
    "            \n",
    "        return prior_probs, likelihood_probs\n",
    "\n",
    "    def fit(self, data):\n",
    "        label_counts = self.count_labels(data)\n",
    "        word_counts = self.count_words(self.wordlist, data)\n",
    "\n",
    "        self.prior_probs, self.likelihood_probs = self.calculate_probability(label_counts, word_counts)\n",
    "\n",
    "        # TO AVOID NUMBER OVERFLOW here we use log probability instead.\n",
    "        \n",
    "        self.log_prior_probs = np.log(self.prior_probs)\n",
    "        self.log_likelihood_probs = np.dstack([np.log(1 - self.likelihood_probs), np.log(self.likelihood_probs)])\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Predict whether email $x is a spam or not.\n",
    "        Returns:\n",
    "            * y: a boolean value indicating whether $x is a spam or not.\n",
    "        \"\"\"        \n",
    "        # proc the data\n",
    "        L = len(self.wordlist)\n",
    "        feature_vector = np.zeros(L, dtype=\"int8\")\n",
    "        word_set = set(x)\n",
    "        for i in range(L):\n",
    "            if self.wordlist[i] in word_set:\n",
    "                feature_vector[i] = 1\n",
    "        \n",
    "        neg, pos = self.log_prior_probs[0], self.log_prior_probs[1]\n",
    "        \n",
    "        for i in range(L):\n",
    "            neg += self.log_likelihood_probs[0, i, feature_vector[i]]\n",
    "            pos += self.log_likelihood_probs[1, i, feature_vector[i]]\n",
    "        \n",
    "        if pos > neg:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b57b4b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.array(train)\n",
    "classifer = Model(wordlist)\n",
    "classifer.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "265e0faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation error, # =  157, % =  15.7000%.\n"
     ]
    }
   ],
   "source": [
    "val_data = np.array(validation)[:1000]\n",
    "error_count = 0\n",
    "total = len(val_data)\n",
    "for mail in val_data:\n",
    "    if mail[0] != classifer.predict(mail[1]):\n",
    "        error_count += 1\n",
    "        \n",
    "error_percentage = error_count*100/total\n",
    "    \n",
    "\n",
    "print(\"Validation error, # = {:>4d}, % = {:>8.4f}%.\".format(error_count, error_percentage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "891592f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n"
     ]
    }
   ],
   "source": [
    "a = \"Fuck your asshole stupid\"\n",
    "a = preproc_text(a)\n",
    "\n",
    "print(\"positive\" if classifer.predict(a)==1 else \"negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9758b3f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38] *",
   "language": "python",
   "name": "conda-env-py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
